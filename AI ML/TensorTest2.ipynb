{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yfinance as yfin\n",
    "import StockPull\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, Dropout, Activation, Dense, LSTM\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "\n",
    "yfin.pdr_override()\n",
    "\n",
    "#load data\n",
    "company = 'tsla'\n",
    "start = dt.datetime(2012,1,1)\n",
    "end = dt.datetime(2022,1,1)\n",
    "\n",
    "data = StockPull.analysisout(company)\n",
    "\n",
    "#prepare data\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaled_data = scaler.fit_transform(data['Price'].values.reshape(-1,1))\n",
    "train_dates = pd.to_datetime(data['Date'])\n",
    "cols = list(data)[1:3]\n",
    "df_for_training = data[cols].astype(float)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_for_training)\n",
    "df_for_training_scaled = scaler.transform(df_for_training)\n",
    "\n",
    "prediction_days = 60\n",
    "n_future = 1\n",
    "n_past = 60\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "trainX = []\n",
    "trainY = []\n",
    "\n",
    "for i in range(n_past, len(df_for_training_scaled) - n_future + 1):\n",
    "    trainX.append(df_for_training_scaled[i - n_past:i, 0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)\n",
    "\n",
    "\n",
    "# for x in range(prediction_days, len(scaled_data)):\n",
    "#     x_train.append(scaled_data[x-prediction_days:x, 0])\n",
    "#     y_train.append(scaled_data[x,0])\n",
    "#\n",
    "# x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "# x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('trainX shape == {}.'.format(trainX.shape))\n",
    "print('trainY shape == {}.'.format(trainY.shape))\n",
    "print(df_for_training_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#build the model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(64, activation='relu', input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "\n",
    "# model.add(LSTM(units=50, return_sequences=True, input_shape = (trainX.shape[1], 1)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50, return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(units=50))\n",
    "# model.add(Dense(units=1)) #prediction of the next closing value)\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer ='adam', loss='mean_squared_error')\n",
    "# model.fit(trainX, trainY, epochs=25, batch_size=32)\n",
    "\n",
    "history = model.fit(trainX, trainY, epochs=25, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TEST THE MODEL ACCURACY\n",
    "\n",
    "test_start = dt.datetime(2022,1,1)\n",
    "test_end = dt.datetime.now()\n",
    "\n",
    "test_data = StockPull.analysisout(company, '5y','1d')\n",
    "actual_prices = test_data ['Price'].values\n",
    "\n",
    "total_dataset = pd.concat((data['Price'], test_data['Price']), axis=0)\n",
    "\n",
    "model_inputs = total_dataset[len(total_dataset) - len(test_data) - prediction_days:].values\n",
    "model_inpts = model_inputs.reshape(-1,1)\n",
    "model_inputs = scaler.transform(model_inpts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#makeprediction on test data\n",
    "\n",
    "x_test = []\n",
    "\n",
    "for x in range(prediction_days, len(model_inputs)):\n",
    "    x_test.append(model_inputs[x-prediction_days:x, 0])\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1],1))\n",
    "\n",
    "predicted_prices = model.predict(x_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot the test predictions\n",
    "plt.plot(actual_prices, color = \"black\")\n",
    "plt.plot(predicted_prices, color = \"green\")\n",
    "plt.title(f\"{company} Share Price\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(f'{company} Share Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Predict next day\n",
    "\n",
    "real_data = [model_inputs[len(model_inputs) + 1 - prediction_days:len(model_inputs+1), 0]]\n",
    "real_data = np.array(real_data)\n",
    "real_data = np.reshape(real_data, (real_data.shape[0], real_data.shape[1],1))\n",
    "\n",
    "prediction =  model.predict(real_data)\n",
    "prediction = scaler.inverse_transform(prediction)\n",
    "print(f\"Prediction: {prediction}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "01c730f715953cdae05f8e4ac25ca6d1b5ea3ce06f18038eaf15eb4c2f30d669"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}